# LLM-Local-Lab - DocumentaciÃ³n Central

**Ãšltima actualizaciÃ³n:** 2025-10-02
**VersiÃ³n del proyecto:** 0.1.0
**MetodologÃ­a:** RPVEA-A (Agent-Augmented Testing-First)

---

## ğŸ¯ NavegaciÃ³n RÃ¡pida

| Necesito... | Voy a... |
|-------------|----------|
| Ver quÃ© modelos tengo disponibles | [`models/local-models-inventory.md`](models/local-models-inventory.md) |
| Saber cÃ³mo ejecutar tests | [`testing/test-suite-reference.md`](testing/test-suite-reference.md) |
| Entender el cÃ³digo del proyecto | [`code-reference/api-index.md`](code-reference/api-index.md) |
| Aprender la metodologÃ­a RPVEA-A | [`workflows/rpvea-agent-integration.md`](workflows/rpvea-agent-integration.md) |
| Configurar un nuevo modelo | [`models/models-registry.md`](models/models-registry.md) |
| Ver especificaciones de hardware | [`hardware/system-specs.md`](hardware/system-specs.md) |
| Consultar benchmarks pasados | [`benchmarks/methodology.md`](benchmarks/methodology.md) |

---

## ğŸ“ Estructura de DocumentaciÃ³n

```
docs/
â”œâ”€â”€ README.md                          # Este archivo (Ã­ndice maestro)
â”œâ”€â”€ models/                            # DocumentaciÃ³n de modelos
â”‚   â”œâ”€â”€ local-models-inventory.md      # âœ… NUEVO: Inventario completo de modelos
â”‚   â””â”€â”€ models-registry.md             # Modelos testeados con resultados
â”œâ”€â”€ testing/                           # DocumentaciÃ³n de testing
â”‚   â”œâ”€â”€ test-suite-reference.md        # âœ… NUEVO: Referencia completa de tests
â”‚   â””â”€â”€ strategy_embedding_benchmark_20251002.md  # Estrategia de testing especÃ­fica
â”œâ”€â”€ code-reference/                    # DocumentaciÃ³n de cÃ³digo
â”‚   â””â”€â”€ api-index.md                   # âœ… NUEVO: Ãndice de clases y funciones
â”œâ”€â”€ workflows/                         # Workflows y metodologÃ­a
â”‚   â””â”€â”€ rpvea-agent-integration.md     # âœ… NUEVO: RPVEA-A framework
â”œâ”€â”€ hardware/                          # Especificaciones de hardware
â”‚   â””â”€â”€ system-specs.md                # Specs del sistema (pendiente)
â””â”€â”€ benchmarks/                        # MetodologÃ­a de benchmarking
    â””â”€â”€ methodology.md                 # CÃ³mo hacer benchmarks (pendiente)
```

---

## ğŸš€ DocumentaciÃ³n Clave (Creada Hoy)

### 1. **Inventario de Modelos Locales** â­
**Archivo:** [`models/local-models-inventory.md`](models/local-models-inventory.md)

**QuÃ© encontrarÃ¡s:**
- âœ… **5 LLMs en Ollama** (gemma2:27b, qwen3-coder:30b, deepseek-r1:8b, etc.)
- âœ… **2 modelos de embeddings** en cachÃ© HF (paraphrase-multilingual, bge-m3-es-legal)
- âœ… **Rutas exactas** a archivos de modelos descargados
- âœ… **CÃ³digo de acceso** (Python, CLI, LangChain)
- âœ… **Benchmarks esperados** para cada modelo
- âœ… **IntegraciÃ³n con Langextract** y RAG-Anything

**CuÃ¡ndo consultar:**
- Antes de ejecutar benchmarks (saber quÃ© modelos hay)
- Al agregar nuevos modelos (ver estructura)
- Para troubleshooting de modelos no encontrados
- Al escribir scripts que usen modelos

**Secciones destacadas:**
- DecisiÃ³n matrix: "Â¿QuÃ© modelo usar para X tarea?"
- Comandos de mantenimiento (limpiar cachÃ©, descargar modelos)
- Rutas completas a modelos descargados

---

### 2. **Referencia de Testing Suite** â­
**Archivo:** [`testing/test-suite-reference.md`](testing/test-suite-reference.md)

**QuÃ© encontrarÃ¡s:**
- âœ… **45 tests documentados** (17 PRE, 12 POST, 16 Integration)
- âœ… **CÃ³mo ejecutar cada suite** (comandos exactos)
- âœ… **QuÃ© valida cada test** (descripciÃ³n detallada)
- âœ… **Troubleshooting** de tests fallidos
- âœ… **Criticality levels** (HIGH/MEDIUM/LOW)

**CuÃ¡ndo consultar:**
- Antes de ejecutar benchmarks (VALIDATE phase)
- Cuando un test falla (troubleshooting)
- Al agregar nuevos tests (seguir convenciones)
- Para entender quÃ© cubren los tests

**Secciones destacadas:**
- Workflow completo RPVEA-A con tests
- Variables globales compartidas (POST-tests)
- Fixtures de pytest (Integration tests)
- ResoluciÃ³n de errores comunes

---

### 3. **Ãndice de API y CÃ³digo** â­
**Archivo:** [`code-reference/api-index.md`](code-reference/api-index.md)

**QuÃ© encontrarÃ¡s:**
- âœ… **1 clase documentada** (LLMBenchmark)
- âœ… **48 funciones indexadas** (todos los mÃ³dulos)
- âœ… **NavegaciÃ³n por lÃ­nea** (ir directo al cÃ³digo)
- âœ… **ParÃ¡metros y return values** documentados
- âœ… **Ejemplos de uso** para cada funciÃ³n

**CuÃ¡ndo consultar:**
- Al escribir cÃ³digo que use benchmarks
- Para entender quÃ© hace una funciÃ³n
- Al buscar dÃ³nde estÃ¡ implementada una feature
- Para ver ejemplos de uso de clases

**Secciones destacadas:**
- Clase `LLMBenchmark` completa (constructor, mÃ©todos)
- PatrÃ³n de timing con CUDA synchronization
- Estructura de JSON output
- TODOs y mejoras futuras

---

### 4. **RPVEA-A Methodology** â­
**Archivo:** [`workflows/rpvea-agent-integration.md`](workflows/rpvea-agent-integration.md)

**QuÃ© encontrarÃ¡s:**
- âœ… **Framework completo RPVEA-A** (5 fases documentadas)
- âœ… **5 subagentes especializados** y cuÃ¡ndo usarlos
- âœ… **Tier system** (Tier 1/2/3 con delegaciÃ³n)
- âœ… **Anti-patterns** a evitar
- âœ… **Ejemplos reales** de workflows

**CuÃ¡ndo consultar:**
- Al iniciar cualquier tarea compleja (Tier 2/3)
- Para entender cuÃ¡ndo usar subagentes
- Al diseÃ±ar testing strategies
- Para seguir best practices del proyecto

**Secciones destacadas:**
- PREPARE phase con @test-architect (testing-first)
- VALIDATE phase (PRE-tests mandatory)
- Delegation matrix por fase y tier
- Decision matrix: cuÃ¡ndo usar quÃ© agentes

---

## ğŸ“– DocumentaciÃ³n por Caso de Uso

### ğŸ¯ Caso 1: "Quiero ejecutar un benchmark de embeddings"

**Flujo RPVEA-A:**

1. **REVIEW (5 min):**
   - Lee: [`models/local-models-inventory.md`](models/local-models-inventory.md)
   - Verifica quÃ© modelos de embeddings tienes
   - Confirma: paraphrase-multilingual y bge-m3-es-legal en cachÃ©

2. **PREPARE (15 min):**
   - Lee: [`testing/test-suite-reference.md`](testing/test-suite-reference.md) â†’ SecciÃ³n PRE-tests
   - Entiende quÃ© validan los 17 PRE-tests
   - Nota: test_model_multilingual_exists puede fallar (OK si modelo en cachÃ©)

3. **VALIDATE (10 min):**
   - Ejecuta: `python tests/pre/test_embedding_prereqs_20251002.py`
   - Si 15+ tests pasan â†’ PROCEED
   - Si <15 pasan â†’ Fix issues

4. **EXECUTE (15-20 min):**
   - Lee: [`code-reference/api-index.md`](code-reference/api-index.md) â†’ Embedding Benchmark
   - Ejecuta: `python benchmarks/scripts/embedding_benchmark.py | tee output.txt`

5. **ASSESS (15 min):**
   - Lee: [`testing/test-suite-reference.md`](testing/test-suite-reference.md) â†’ SecciÃ³n POST-tests
   - Ejecuta: `python tests/post/test_embedding_success_20251002.py`
   - Valida: speedup >= 2x

**Total time:** ~60-70 min (incluye ejecuciÃ³n de benchmark)

---

### ğŸ¯ Caso 2: "Quiero agregar un nuevo LLM para testing"

**Flujo:**

1. **Descargar con Ollama:**
   ```bash
   ollama pull llama3.1:8b
   ```

2. **Actualizar inventario:**
   - Edita: [`models/local-models-inventory.md`](models/local-models-inventory.md)
   - Agrega entrada en tabla de LLMs
   - Documenta: tamaÃ±o, parÃ¡metros, VRAM estimado

3. **Crear configuraciÃ³n (opcional):**
   - Crea: `models/configs/llama-3.1-8b.yaml`
   - Sigue formato de otros configs

4. **Ejecutar benchmark:**
   - Lee: [`code-reference/api-index.md`](code-reference/api-index.md) â†’ LLMBenchmark
   - Ejecuta:
     ```bash
     python benchmarks/scripts/llm_inference_benchmark.py \
         --model llama3.1:8b \
         --device cuda:0 \
         --runs 10
     ```

5. **Documentar resultados:**
   - Agrega a: [`models/models-registry.md`](models/models-registry.md)
   - Include: throughput, latency, VRAM usage

---

### ğŸ¯ Caso 3: "Un test estÃ¡ fallando, no sÃ© por quÃ©"

**Troubleshooting con docs:**

1. **Identificar el test:**
   - Anota el nombre exacto (ej: `test_model_multilingual_exists`)

2. **Consultar referencia:**
   - Abre: [`testing/test-suite-reference.md`](testing/test-suite-reference.md)
   - Busca el test por nombre (Ctrl+F)

3. **Leer documentaciÃ³n del test:**
   - **QuÃ© valida:** "Modelo en Hugging Face Hub (API check)"
   - **CrÃ­tico:** Medium (pero modelo en cachÃ© funciona)
   - **Si falla:** Opciones A, B, C documentadas

4. **Ver secciÃ³n Troubleshooting:**
   - Encuentra: "PRE-test: test_model_multilingual_exists() falla con 401"
   - SoluciÃ³n: "Ignorar si modelo en cachÃ©"
   - Verificar:
     ```bash
     ls ~/.cache/huggingface/hub/models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2
     ```

5. **Confirmar con inventario:**
   - Abre: [`models/local-models-inventory.md`](models/local-models-inventory.md)
   - Busca ruta del modelo
   - Confirma: modelo descargado 2025-08-26 (OK)

**DecisiÃ³n:** Ignorar fallo de API, modelo local funciona.

---

### ğŸ¯ Caso 4: "Necesito entender cÃ³mo funciona X funciÃ³n"

**NavegaciÃ³n de cÃ³digo:**

1. **Buscar en API index:**
   - Abre: [`code-reference/api-index.md`](code-reference/api-index.md)
   - Ctrl+F: nombre de funciÃ³n

2. **Ver documentaciÃ³n:**
   - **ParÃ¡metros:** tipos y defaults
   - **Retorna:** estructura del output
   - **UbicaciÃ³n:** archivo y lÃ­nea exacta
   - **Ejemplo de uso:** cÃ³digo ejecutable

3. **Ir al cÃ³digo fuente:**
   - Abre archivo mencionado
   - Navega a lÃ­nea exacta
   - Lee implementaciÃ³n

**Ejemplo:**
- Busco: "get_gpu_memory"
- Encuentro: llm_inference_benchmark.py lÃ­neas 66-78
- Leo: mÃ©todo de clase LLMBenchmark
- Veo ejemplo: Dict con gpu_X_allocated_gb

---

## ğŸ” BÃºsquedas Frecuentes

### "Â¿CÃ³mo acceder a modelo X?"

**Respuesta en:** [`models/local-models-inventory.md`](models/local-models-inventory.md)

**Secciones:**
- LLMs â†’ "Acceso a Modelos Ollama" (3 mÃ©todos)
- Embeddings â†’ "Acceso (Python)" con cÃ³digo

---

### "Â¿QuÃ© tests debo ejecutar antes de X?"

**Respuesta en:** [`testing/test-suite-reference.md`](testing/test-suite-reference.md)

**SecciÃ³n:** "GuÃ­a de Uso RÃ¡pida" â†’ Workflow Completo

---

### "Â¿CuÃ¡ndo usar @test-architect?"

**Respuesta en:** [`workflows/rpvea-agent-integration.md`](workflows/rpvea-agent-integration.md)

**SecciÃ³n:** "Phase P: PREPARE" â†’ Critical Delegations

---

### "Â¿QuÃ© modelo de embeddings es mejor para Y?"

**Respuesta en:** [`models/local-models-inventory.md`](models/local-models-inventory.md)

**SecciÃ³n:** "GuÃ­a RÃ¡pida de Decisiones" â†’ Diagrama de flujo

---

## ğŸ“Š EstadÃ­sticas de DocumentaciÃ³n

**Documentos creados hoy:** 4
**PÃ¡ginas totales:** ~50 pÃ¡ginas (estimado en Markdown)
**Funciones documentadas:** 48
**Tests documentados:** 45
**Modelos catalogados:** 7 (5 LLM + 2 Embedding)
**Tiempo de creaciÃ³n:** ~2 horas (automated by @documentation-writer + Claude)

**Cobertura:**
- âœ… **100%** de modelos locales inventariados
- âœ… **100%** de tests documentados
- âœ… **100%** de funciones pÃºblicas documentadas
- âœ… **100%** de workflows RPVEA-A documentados

---

## ğŸš§ DocumentaciÃ³n Pendiente

### High Priority
- [ ] `hardware/system-specs.md` - Especificaciones completas del hardware
- [ ] `benchmarks/methodology.md` - MetodologÃ­a de benchmarking detallada
- [ ] `models/models-registry.md` - Registry de modelos testeados

### Medium Priority
- [ ] `workflows/agent-usage.md` - GuÃ­a de uso de subagentes
- [ ] `tutorials/first-benchmark.md` - Tutorial paso a paso
- [ ] `troubleshooting.md` - Troubleshooting centralizado

### Low Priority
- [ ] `performance-tuning.md` - OptimizaciÃ³n de rendimiento
- [ ] `dual-gpu-setup.md` - ConfiguraciÃ³n dual-GPU
- [ ] `changelog.md` - Changelog del proyecto

---

## ğŸ”„ Mantenimiento de DocumentaciÃ³n

### CuÃ¡ndo Actualizar Docs

**Triggers automÃ¡ticos (RPVEA-A):**
- **ASSESS phase:** @documentation-writer actualiza registry
- **New model added:** Actualizar local-models-inventory.md
- **New test created:** Actualizar test-suite-reference.md
- **New function:** Actualizar api-index.md

### Proceso de ActualizaciÃ³n

1. **Identificar secciÃ³n afectada**
2. **Editar archivo correspondiente**
3. **Actualizar "Ãšltima actualizaciÃ³n" en header**
4. **Agregar entrada en Changelog (si existe)**
5. **Git commit:** `docs: update [section] - [reason]`

### Convenciones de Formato

**Headers:**
- Nivel 1 (`#`): TÃ­tulo del documento
- Nivel 2 (`##`): Secciones principales
- Nivel 3 (`###`): Subsecciones
- Nivel 4 (`####`): Detalles especÃ­ficos

**Code Blocks:**
- Usar \`\`\`python, \`\`\`bash, etc. (syntax highlighting)
- Incluir comentarios explicativos
- Mostrar output esperado cuando relevante

**Tablas:**
- Usar para comparaciones y referencias rÃ¡pidas
- Alinear columnas para legibilidad
- Incluir headers descriptivos

**Links:**
- Usar paths relativos (`models/inventory.md`)
- Verificar que links funcionen
- Usar nombres descriptivos, no URLs

---

## ğŸ“ Aprendizajes y Best Practices

### Lo que Funciona Bien

âœ… **Documentar mientras se crea cÃ³digo** (RPVEA-A ASSESS phase)
- Contexto fresco en memoria
- No necesitas "recordar" despuÃ©s
- @documentation-writer automatiza mucho

âœ… **Ãndices centralizados** (este README)
- FÃ¡cil navegaciÃ³n
- No buscar en mÃºltiples lugares
- Quick reference para Claude Code

âœ… **Troubleshooting inline** (en test-suite-reference.md)
- Soluciones al lado del problema
- Reduce tiempo de debugging
- Basado en experiencia real

âœ… **CÃ³digo ejecutable en docs** (api-index.md)
- Copiar-pegar directo
- Ejemplos verificables
- Aprende haciendo

### Lo que Evitamos

âŒ **Docs genÃ©ricos sin ejemplos**
- DifÃ­cil de usar
- No actionable

âŒ **DocumentaciÃ³n desactualizada**
- Peor que no tener docs
- Confusion y errores

âŒ **Falta de navegaciÃ³n**
- Tiempo perdido buscando
- FrustraciÃ³n

âŒ **No documentar edge cases**
- Repiten mismos errores
- Debugging repetitivo

---

## ğŸ“ Soporte y ContribuciÃ³n

### Â¿Falta documentaciÃ³n?

**Proceso para solicitar docs:**
1. Abre issue en GitHub (si aplicable)
2. Describe quÃ© necesitas documentar
3. Indica caso de uso o problema
4. @documentation-writer generarÃ¡ draft

### Â¿Encontraste un error en docs?

**Proceso de correcciÃ³n:**
1. Nota la ubicaciÃ³n exacta (archivo, secciÃ³n)
2. Describe el error
3. Sugiere correcciÃ³n
4. Submit PR o issue

### Contribuir con DocumentaciÃ³n

**Guidelines:**
- Seguir formato existente
- Incluir ejemplos ejecutables
- Actualizar Ã­ndice maestro (este README)
- Testing antes de commit (verificar links)

---

## ğŸ”— Enlaces Externos

**Proyectos Relacionados:**
- Langextract: `C:\Users\Gamer\Dev\Langextract`
- RAG-Anything: `C:\Users\Gamer\Dev\RAG-Anything`

**DocumentaciÃ³n TÃ©cnica:**
- sentence-transformers: https://www.sbert.net/
- Ollama API: https://github.com/ollama/ollama/blob/main/docs/api.md
- Hugging Face Hub: https://huggingface.co/docs
- PyTorch CUDA: https://pytorch.org/docs/stable/cuda.html

**MetodologÃ­a:**
- RPVEA Framework: `C:\Users\Gamer\Downloads\METODOLOGIA DESARROLLO`

---

## ğŸ“ Changelog de DocumentaciÃ³n

**2025-10-02:**
- âœ… Creado README maestro de documentaciÃ³n
- âœ… Inventario completo de modelos (`local-models-inventory.md`)
- âœ… Referencia de testing suite (`test-suite-reference.md`)
- âœ… Ãndice de API y cÃ³digo (`api-index.md`)
- âœ… RPVEA-A methodology (`rpvea-agent-integration.md`)
- âœ… @test-architect agent specification
- âœ… Estructura de docs/ organizada

**Cobertura inicial:** 4 documentos principales, ~50 pÃ¡ginas, 100% de cÃ³digo actual documentado

---

**Mantenido por:** LLM-Local-Lab
**MetodologÃ­a:** RPVEA-A (Agent-Augmented Testing-First)
**Generado con:** Claude Code + @documentation-writer
